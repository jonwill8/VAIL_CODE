{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP_Autocomplete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5b1f275ef9c14e61ba49fc0c4339246e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_fe79529002814a14a8544041629b2719",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_a653270828a14d3fa156f84a90248388",
       "IPY_MODEL_90cff94cc1b64e7fa6f96bae187e61f1"
      ]
     }
    },
    "fe79529002814a14a8544041629b2719": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a653270828a14d3fa156f84a90248388": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_956c1906c7de475f96f49ff1ee4bd6ab",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 487,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 487,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e5e501748f9643b889bfb70062468af7"
     }
    },
    "90cff94cc1b64e7fa6f96bae187e61f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_66dc7919cfee4778a77c0ff02e773730",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 487/487 [00:00&lt;00:00, 716B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_68d717f04b904031900c9efa5a7b48e6"
     }
    },
    "956c1906c7de475f96f49ff1ee4bd6ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e5e501748f9643b889bfb70062468af7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "66dc7919cfee4778a77c0ff02e773730": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "68d717f04b904031900c9efa5a7b48e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "81bd0fe9a64d43efa1f44dff2eb0a9f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_1de72cce7e534381a02bab14c90e1c50",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_684f0eafadb848cab61e2716f00ecb3c",
       "IPY_MODEL_02a4648bafd94a7795def83cf6543715"
      ]
     }
    },
    "1de72cce7e534381a02bab14c90e1c50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "684f0eafadb848cab61e2716f00ecb3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_9abaf0ba7b064fb1bd4bb8a2ae2a2a59",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 954339,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 954339,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_131d1f02c6544c5fa2061dae9d890498"
     }
    },
    "02a4648bafd94a7795def83cf6543715": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_08213ab37c47495abe05edd80430ef98",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 954k/954k [00:00&lt;00:00, 1.86MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_69d792d8132c408c99d461f3c740c805"
     }
    },
    "9abaf0ba7b064fb1bd4bb8a2ae2a2a59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "131d1f02c6544c5fa2061dae9d890498": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "08213ab37c47495abe05edd80430ef98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "69d792d8132c408c99d461f3c740c805": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "bd4011d5955c4a96b315f949132cd633": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_ed5a2cb7bb9b4cdcbefee866e5e7db50",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_9adaf55eeed0469c857e70eea521bc56",
       "IPY_MODEL_c0a7137a4c91410999a07d61f240de97"
      ]
     }
    },
    "ed5a2cb7bb9b4cdcbefee866e5e7db50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9adaf55eeed0469c857e70eea521bc56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_3340b5b3233c4865aa9dfad057a8e809",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 512068,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 512068,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_76133744796a478da48c83406d6ae575"
     }
    },
    "c0a7137a4c91410999a07d61f240de97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a538bae985b8402db2852ac9abb17ca2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 512k/512k [00:00&lt;00:00, 1.66MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d14664c3c23e4f7d9cccfbc7b388f446"
     }
    },
    "3340b5b3233c4865aa9dfad057a8e809": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "76133744796a478da48c83406d6ae575": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a538bae985b8402db2852ac9abb17ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d14664c3c23e4f7d9cccfbc7b388f446": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a04031238f6746d7bf3c371aed1bb690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_0dde75f5a08b4c9e8133bb0d586dd0ba",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0f2ef289110e41c2810e9c436fe18415",
       "IPY_MODEL_016bd1d96c1342b7b76c0aebfcbe8cf7"
      ]
     }
    },
    "0dde75f5a08b4c9e8133bb0d586dd0ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0f2ef289110e41c2810e9c436fe18415": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_2d2bb4107ab0402c9189cbe391a2d006",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 16,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 16,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_df0892f3773e4bc08da3ea1adb51b69b"
     }
    },
    "016bd1d96c1342b7b76c0aebfcbe8cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8aff1b6f9b784a2f82d6dcbda2b72a15",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 16.0/16.0 [00:00&lt;00:00, 188B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3bcf2880f6d54af2846f15c48d47aa62"
     }
    },
    "2d2bb4107ab0402c9189cbe391a2d006": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "df0892f3773e4bc08da3ea1adb51b69b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8aff1b6f9b784a2f82d6dcbda2b72a15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3bcf2880f6d54af2846f15c48d47aa62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "008e5e38315c4a7cbb03f7f579812690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_6844b9a0e10d438ab86c7f20d4a145d0",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_64f40dbb1e3a4b87933e64f72a224507",
       "IPY_MODEL_20d2187dfc94492985d4b3aa8aad2352"
      ]
     }
    },
    "6844b9a0e10d438ab86c7f20d4a145d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "64f40dbb1e3a4b87933e64f72a224507": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_34770b3ee4dc40b4a5db4191f8d15657",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 501202014,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 501202014,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_24bc4f6d88bf4bd6a9ac9e6292ff7c20"
     }
    },
    "20d2187dfc94492985d4b3aa8aad2352": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_f0f990ce9c9f4f99ab40ad98539c9b0f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 501M/501M [00:11&lt;00:00, 43.9MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7ab3badac027410f87ac1425795c71f7"
     }
    },
    "34770b3ee4dc40b4a5db4191f8d15657": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "24bc4f6d88bf4bd6a9ac9e6292ff7c20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f0f990ce9c9f4f99ab40ad98539c9b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7ab3badac027410f87ac1425795c71f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oit-RTHTjXg3"
   },
   "source": [
    "# This notebook corresponds with the Day 22 VAIL Action Item\n",
    "\n",
    "### Experimenting with Autocomplete using the roBERTa model\n",
    "\n",
    "#### Source [Article](https://colab.research.google.com/drive/1mXWYYkB9UjRdklPVSDvAcUDralmv3Pgv#scrollTo=-c0w1Xt2bnqR)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSze0jeYqjn8",
    "outputId": "63f6fb8f-718a-4e1d-e495-dccd0b33c8f4"
   },
   "source": [
    "#trainig the roBERTa model on Spanish text:\n",
    "!pip install transformers==2.8.0"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.17.18)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.95)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.18 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.20.18)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.18->boto3->transformers==2.8.0) (2.8.1)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zJiTivRkqvha"
   },
   "source": [
    "#pulling a spanish dataset for fitting our model:\n",
    "import os\n",
    "\n",
    "# Download and unzip movie substitle dataset\n",
    "if not os.path.exists('data/dataset.txt'):\n",
    "  !wget \"https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/es.txt.gz\" -O dataset.txt.gz\n",
    "  !gzip -d dataset.txt.gz\n",
    "  !mkdir data\n",
    "  !mv dataset.txt data"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYqjIS7FrDTR",
    "outputId": "ffc3a2d5-fb73-4b52-9206-8143e551f0f9"
   },
   "source": [
    "# showing the total line # from the dataset we pulled \n",
    "!wc -l data/dataset.txt\n",
    "# showing som random lines from the dataset\n",
    "!shuf -n 5 data/dataset.txt"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "179287150 data/dataset.txt\n",
      "Â¿QuÃ© estÃ¡ pasando?\n",
      "Se enojaron.\n",
      "- Silene lo sabe.\n",
      "Supongo que eso no es elitista.\n",
      "Â¡Ahora vete!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijHvGhcIrNJ7",
    "outputId": "b8165cec-10ff-4173-da6b-b12ce8c58855"
   },
   "source": [
    "# pulling first 1,000,000 lines for training\n",
    "TRAIN_SIZE = 1000000\n",
    "!(head -n $TRAIN_SIZE data/dataset.txt) > data/train.txt\n",
    "# pulling next 10,000 lines for validation\n",
    "!(sed -n {TRAIN_SIZE + 1},{TRAIN_SIZE + VAL_SIZE}p data/dataset.txt) > data/dev.txt"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "sed: -e expression #1, char 0: unmatched `{'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMvbppL1sE38",
    "outputId": "86a21f6a-aed6-4ebf-c117-ea33fed051be"
   },
   "source": [
    "!pip install tokenizers"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.5.2)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PE-Tp3X-rq-M"
   },
   "source": [
    "#training a tokenizer specific to spanish:\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "path = \"data/train.txt\"\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=path,\n",
    "                vocab_size=50265,\n",
    "                min_frequency=2,\n",
    "                special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
    "\n",
    "# Save files to disk\n",
    "!mkdir -p \"/content/models\""
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XLCggc57hKw",
    "outputId": "d6c766fd-3a73-488b-e97f-534ccd18602f"
   },
   "source": [
    "tokenizer.save(\"/content/models\")"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/content/models/vocab.json', '/content/models/merges.txt']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sDpK67NnsBNN"
   },
   "source": [
    "import json\n",
    "config = {\n",
    "\t\"architectures\": [\n",
    "\t\t\"RobertaForMaskedLM\"\n",
    "\t],\n",
    "\t\"attention_probs_dropout_prob\": 0.1,\n",
    "\t\"hidden_act\": \"gelu\",\n",
    "\t\"hidden_dropout_prob\": 0.1,\n",
    "\t\"hidden_size\": 768,\n",
    "\t\"initializer_range\": 0.02,\n",
    "\t\"intermediate_size\": 3072,\n",
    "\t\"layer_norm_eps\": 1e-05,\n",
    "\t\"max_position_embeddings\": 514,\n",
    "\t\"model_type\": \"roberta\",\n",
    "\t\"num_attention_heads\": 12,\n",
    "\t\"num_hidden_layers\": 12,\n",
    "\t\"type_vocab_size\": 1,\n",
    "\t\"vocab_size\": 50265\n",
    "}\n",
    "\n",
    "with open(\"models/config.json\", 'w') as fp:\n",
    "    json.dump(config, fp)\n",
    "\n",
    "tokenizer_config = {\"max_len\": 512}\n",
    "\n",
    "with open(\"models/tokenizer_config.json\", 'w') as fp:\n",
    "    json.dump(tokenizer_config, fp)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAQsz3NcuI43",
    "outputId": "0366f0b1-fa6c-4639-996f-7749241ea581"
   },
   "source": [
    "#training model:\n",
    "!wget -c https://raw.githubusercontent.com/chriskhanhtran/spanish-bert/master/run_language_modeling.py"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2021-03-02 03:16:11--  https://raw.githubusercontent.com/chriskhanhtran/spanish-bert/master/run_language_modeling.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34328 (34K) [text/plain]\n",
      "Saving to: â€˜run_language_modeling.pyâ€™\n",
      "\n",
      "\rrun_language_modeli   0%[                    ]       0  --.-KB/s               \rrun_language_modeli 100%[===================>]  33.52K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-03-02 03:16:11 (125 MB/s) - â€˜run_language_modeling.pyâ€™ saved [34328/34328]\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qNu2Qq2-vkeF"
   },
   "source": [
    "# Model paths\n",
    "MODEL_TYPE = \"roberta\"\n",
    "MODEL_DIR = \"models\" \n",
    "OUTPUT_DIR = \"models/output\" \n",
    "TRAIN_PATH = \"data/train.txt\" \n",
    "EVAL_PATH = \"data/dev.txt\" "
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pvkJwDeCvvNg"
   },
   "source": [
    "cmd = \"\"\"python run_language_modeling.py \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --model_type {model_type} \\\n",
    "    --mlm \\\n",
    "    --config_name {config_name} \\\n",
    "    --tokenizer_name {tokenizer_name} \\\n",
    "    {line_by_line} \\\n",
    "    {should_continue} \\\n",
    "    {model_name_or_path} \\\n",
    "    --train_data_file {train_path} \\\n",
    "    --eval_data_file {eval_path} \\\n",
    "    --do_train \\\n",
    "    {do_eval} \\\n",
    "    {evaluate_during_training} \\\n",
    "    --overwrite_output_dir \\\n",
    "    --block_size 512 \\\n",
    "    --max_step 25 \\\n",
    "    --warmup_steps 10 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --adam_epsilon 1e-6 \\\n",
    "    --max_grad_norm 100.0 \\\n",
    "    --save_total_limit 10 \\\n",
    "    --save_steps 10 \\\n",
    "    --logging_steps 2 \\\n",
    "    --seed 42\n",
    "\"\"\""
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ulpje8j8vy8o"
   },
   "source": [
    "train_params = {\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"model_type\": MODEL_TYPE,\n",
    "    \"config_name\": MODEL_DIR,\n",
    "    \"tokenizer_name\": MODEL_DIR,\n",
    "    \"train_path\": TRAIN_PATH,\n",
    "    \"eval_path\": EVAL_PATH,\n",
    "    \"do_eval\": \"--do_eval\",\n",
    "    \"evaluate_during_training\": \"\",\n",
    "    \"line_by_line\": \"\",\n",
    "    \"should_continue\": \"\",\n",
    "    \"model_name_or_path\": \"\",\n",
    "}"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-neoFVNwwJjB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e74d854d-90de-40ae-e915-045aa59a70a4"
   },
   "source": [
    "!pip install tensorboard==2.1.0\n",
    "!tensorboard dev upload --logdir runs"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard==2.1.0 in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (1.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (0.4.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (0.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (3.12.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (0.36.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (1.27.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (53.0.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0) (1.19.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.1.0) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (4.7.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==2.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==2.1.0) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.1.0) (0.4.8)\n",
      "2021-03-02 03:21:53.280821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "TensorBoard.dev now supports the \"graphs\", \"histograms\", \"hparams\", and \"text\" plugins. To upload data for these plugins, please upgrade to TensorBoard 2.2.2 or newer.\n",
      "Upload started and will continue reading any new data as it's added\n",
      "to the logdir. To stop uploading, press Ctrl-C.\n",
      "View your TensorBoard live at: https://tensorboard.dev/experiment/TZv7jTauQVe9yp1DXjKjvg/\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_main.py\", line 426, in execute\n",
      "    uploader.start_uploading()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader.py\", line 111, in start_uploading\n",
      "    self._upload_once()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader.py\", line 116, in _upload_once\n",
      "    self._rate_limiter.tick()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/util.py\", line 41, in tick\n",
      "    self._time.sleep(wait_secs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/main.py\", line 66, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/program.py\", line 268, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_main.py\", line 579, in run\n",
      "    return _run(flags)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_main.py\", line 259, in _run\n",
      "    intent.execute(server_info, channel)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_main.py\", line 431, in execute\n",
      "    print()\n",
      "KeyboardInterrupt\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ozZEmilxwMlF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4af8bfe9-1f55-4bb3-d9ee-51ccdbba9b22"
   },
   "source": [
    "!{cmd.format(**train_params)}"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2021-03-02 03:22:47.700670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "03/02/2021 03:22:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "03/02/2021 03:22:49 - INFO - transformers.configuration_utils -   loading configuration file models/config.json\n",
      "03/02/2021 03:22:49 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/02/2021 03:22:49 - INFO - transformers.configuration_utils -   loading configuration file models/config.json\n",
      "03/02/2021 03:22:49 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   Model name 'models' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'models' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   Didn't find file models/added_tokens.json. We won't load it.\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   Didn't find file models/special_tokens_map.json. We won't load it.\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   loading file models/vocab.json\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   loading file models/merges.txt\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/02/2021 03:22:49 - INFO - transformers.tokenization_utils -   loading file models/tokenizer_config.json\n",
      "03/02/2021 03:22:49 - INFO - __main__ -   Training new model from scratch\n",
      "03/02/2021 03:23:09 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-06, block_size=512, cache_dir=None, config_name='models', device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='data/dev.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=4, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=2, max_grad_norm=100.0, max_steps=25, mlm=True, mlm_probability=0.15, model_name_or_path=None, model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='models/output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=10, save_total_limit=10, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name='models', train_data_file='data/train.txt', warmup_steps=10, weight_decay=0.01)\n",
      "03/02/2021 03:23:09 - INFO - __main__ -   Creating features from dataset file at data\n",
      "03/02/2021 03:23:39 - INFO - __main__ -   Saving features into cached file data/roberta_cached_lm_510_train.txt\n",
      "03/02/2021 03:23:39 - INFO - __main__ -   ***** Running training *****\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Num examples = 15932\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Num Epochs = 1\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Gradient Accumulation steps = 4\n",
      "03/02/2021 03:23:39 - INFO - __main__ -     Total optimization steps = 25\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/3983 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   0% 1/3983 [00:00<46:19,  1.43it/s]\u001B[A\n",
      "Iteration:   0% 2/3983 [00:01<42:47,  1.55it/s]\u001B[A\n",
      "Iteration:   0% 3/3983 [00:01<40:36,  1.63it/s]\u001B[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "Iteration:   0% 4/3983 [00:02<40:09,  1.65it/s]\u001B[A\n",
      "Iteration:   0% 5/3983 [00:02<38:41,  1.71it/s]\u001B[A\n",
      "Iteration:   0% 6/3983 [00:03<37:39,  1.76it/s]\u001B[A\n",
      "Iteration:   0% 7/3983 [00:03<36:58,  1.79it/s]\u001B[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "\n",
      "Iteration:   0% 8/3983 [00:04<37:38,  1.76it/s]\u001B[A\n",
      "Iteration:   0% 9/3983 [00:05<36:46,  1.80it/s]\u001B[A\n",
      "Iteration:   0% 10/3983 [00:05<36:28,  1.82it/s]\u001B[A\n",
      "Iteration:   0% 11/3983 [00:06<36:00,  1.84it/s]\u001B[A\n",
      "Iteration:   0% 12/3983 [00:06<36:49,  1.80it/s]\u001B[A\n",
      "Iteration:   0% 13/3983 [00:07<36:07,  1.83it/s]\u001B[A\n",
      "Iteration:   0% 14/3983 [00:07<36:05,  1.83it/s]\u001B[A\n",
      "Iteration:   0% 15/3983 [00:08<35:42,  1.85it/s]\u001B[A\n",
      "Iteration:   0% 16/3983 [00:08<36:40,  1.80it/s]\u001B[A\n",
      "Iteration:   0% 17/3983 [00:09<36:09,  1.83it/s]\u001B[A\n",
      "Iteration:   0% 18/3983 [00:09<36:07,  1.83it/s]\u001B[A\n",
      "Iteration:   0% 19/3983 [00:10<35:48,  1.84it/s]\u001B[A\n",
      "Iteration:   1% 20/3983 [00:11<36:49,  1.79it/s]\u001B[A\n",
      "Iteration:   1% 21/3983 [00:11<36:25,  1.81it/s]\u001B[A\n",
      "Iteration:   1% 22/3983 [00:12<36:21,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 23/3983 [00:12<35:59,  1.83it/s]\u001B[A\n",
      "Iteration:   1% 24/3983 [00:13<36:57,  1.79it/s]\u001B[A\n",
      "Iteration:   1% 25/3983 [00:13<36:32,  1.81it/s]\u001B[A\n",
      "Iteration:   1% 26/3983 [00:14<36:25,  1.81it/s]\u001B[A\n",
      "Iteration:   1% 27/3983 [00:14<36:02,  1.83it/s]\u001B[A\n",
      "Iteration:   1% 28/3983 [00:15<36:57,  1.78it/s]\u001B[A\n",
      "Iteration:   1% 29/3983 [00:16<36:15,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 30/3983 [00:16<36:08,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 31/3983 [00:17<35:48,  1.84it/s]\u001B[A\n",
      "Iteration:   1% 32/3983 [00:17<36:42,  1.79it/s]\u001B[A\n",
      "Iteration:   1% 33/3983 [00:18<36:15,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 34/3983 [00:18<36:14,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 35/3983 [00:19<35:50,  1.84it/s]\u001B[A\n",
      "Iteration:   1% 36/3983 [00:19<36:49,  1.79it/s]\u001B[A\n",
      "Iteration:   1% 37/3983 [00:20<36:11,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 38/3983 [00:21<36:05,  1.82it/s]\u001B[A\n",
      "Iteration:   1% 39/3983 [00:21<35:57,  1.83it/s]\u001B[A03/02/2021 03:24:01 - INFO - transformers.configuration_utils -   Configuration saved in models/output/checkpoint-10/config.json\n",
      "03/02/2021 03:24:03 - INFO - transformers.modeling_utils -   Model weights saved in models/output/checkpoint-10/pytorch_model.bin\n",
      "03/02/2021 03:24:03 - INFO - __main__ -   Saving model checkpoint to models/output/checkpoint-10\n",
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "03/02/2021 03:24:08 - INFO - __main__ -   Saving optimizer and scheduler states to models/output/checkpoint-10\n",
      "\n",
      "Iteration:   1% 40/3983 [00:28<2:44:52,  2.51s/it]\u001B[A\n",
      "Iteration:   1% 41/3983 [00:29<2:07:19,  1.94s/it]\u001B[A\n",
      "Iteration:   1% 42/3983 [00:29<1:39:38,  1.52s/it]\u001B[A\n",
      "Iteration:   1% 43/3983 [00:30<1:20:42,  1.23s/it]\u001B[A\n",
      "Iteration:   1% 44/3983 [00:30<1:08:03,  1.04s/it]\u001B[A\n",
      "Iteration:   1% 45/3983 [00:31<58:28,  1.12it/s]  \u001B[A\n",
      "Iteration:   1% 46/3983 [00:32<51:47,  1.27it/s]\u001B[A\n",
      "Iteration:   1% 47/3983 [00:32<46:58,  1.40it/s]\u001B[A\n",
      "Iteration:   1% 48/3983 [00:33<44:41,  1.47it/s]\u001B[A\n",
      "Iteration:   1% 49/3983 [00:33<41:57,  1.56it/s]\u001B[A\n",
      "Iteration:   1% 50/3983 [00:34<40:08,  1.63it/s]\u001B[A\n",
      "Iteration:   1% 51/3983 [00:34<38:55,  1.68it/s]\u001B[A\n",
      "Iteration:   1% 52/3983 [00:35<39:12,  1.67it/s]\u001B[A\n",
      "Iteration:   1% 53/3983 [00:35<38:12,  1.71it/s]\u001B[A\n",
      "Iteration:   1% 54/3983 [00:36<37:33,  1.74it/s]\u001B[A\n",
      "Iteration:   1% 55/3983 [00:37<37:15,  1.76it/s]\u001B[A\n",
      "Iteration:   1% 56/3983 [00:37<37:56,  1.72it/s]\u001B[A\n",
      "Iteration:   1% 57/3983 [00:38<37:28,  1.75it/s]\u001B[A\n",
      "Iteration:   1% 58/3983 [00:38<37:16,  1.76it/s]\u001B[A\n",
      "Iteration:   1% 59/3983 [00:39<37:04,  1.76it/s]\u001B[A\n",
      "Iteration:   2% 60/3983 [00:39<37:53,  1.73it/s]\u001B[A\n",
      "Iteration:   2% 61/3983 [00:40<37:32,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 62/3983 [00:41<37:19,  1.75it/s]\u001B[A\n",
      "Iteration:   2% 63/3983 [00:41<37:15,  1.75it/s]\u001B[A\n",
      "Iteration:   2% 64/3983 [00:42<38:11,  1.71it/s]\u001B[A\n",
      "Iteration:   2% 65/3983 [00:42<37:44,  1.73it/s]\u001B[A\n",
      "Iteration:   2% 66/3983 [00:43<37:30,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 67/3983 [00:43<37:22,  1.75it/s]\u001B[A\n",
      "Iteration:   2% 68/3983 [00:44<38:11,  1.71it/s]\u001B[A\n",
      "Iteration:   2% 69/3983 [00:45<37:44,  1.73it/s]\u001B[A\n",
      "Iteration:   2% 70/3983 [00:45<37:33,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 71/3983 [00:46<37:23,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 72/3983 [00:46<38:18,  1.70it/s]\u001B[A\n",
      "Iteration:   2% 73/3983 [00:47<37:39,  1.73it/s]\u001B[A\n",
      "Iteration:   2% 74/3983 [00:48<37:26,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 75/3983 [00:48<37:20,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 76/3983 [00:49<38:09,  1.71it/s]\u001B[A\n",
      "Iteration:   2% 77/3983 [00:49<37:43,  1.73it/s]\u001B[A\n",
      "Iteration:   2% 78/3983 [00:50<37:27,  1.74it/s]\u001B[A\n",
      "Iteration:   2% 79/3983 [00:50<37:19,  1.74it/s]\u001B[A03/02/2021 03:24:31 - INFO - transformers.configuration_utils -   Configuration saved in models/output/checkpoint-20/config.json\n",
      "03/02/2021 03:24:32 - INFO - transformers.modeling_utils -   Model weights saved in models/output/checkpoint-20/pytorch_model.bin\n",
      "03/02/2021 03:24:32 - INFO - __main__ -   Saving model checkpoint to models/output/checkpoint-20\n",
      "03/02/2021 03:24:47 - INFO - __main__ -   Saving optimizer and scheduler states to models/output/checkpoint-20\n",
      "\n",
      "Iteration:   2% 80/3983 [01:07<5:43:30,  5.28s/it]\u001B[A\n",
      "Iteration:   2% 81/3983 [01:07<4:12:04,  3.88s/it]\u001B[A\n",
      "Iteration:   2% 82/3983 [01:08<3:07:41,  2.89s/it]\u001B[A\n",
      "Iteration:   2% 83/3983 [01:08<2:22:31,  2.19s/it]\u001B[A\n",
      "Iteration:   2% 84/3983 [01:09<1:52:02,  1.72s/it]\u001B[A\n",
      "Iteration:   2% 85/3983 [01:10<1:29:25,  1.38s/it]\u001B[A\n",
      "Iteration:   2% 86/3983 [01:10<1:13:52,  1.14s/it]\u001B[A\n",
      "Iteration:   2% 87/3983 [01:11<1:02:58,  1.03it/s]\u001B[A\n",
      "Iteration:   2% 88/3983 [01:11<56:26,  1.15it/s]  \u001B[A\n",
      "Iteration:   2% 89/3983 [01:12<50:49,  1.28it/s]\u001B[A\n",
      "Iteration:   2% 90/3983 [01:13<46:55,  1.38it/s]\u001B[A\n",
      "Iteration:   2% 91/3983 [01:13<44:20,  1.46it/s]\u001B[A\n",
      "Iteration:   2% 92/3983 [01:14<43:24,  1.49it/s]\u001B[A\n",
      "Iteration:   2% 93/3983 [01:14<41:46,  1.55it/s]\u001B[A\n",
      "Iteration:   2% 94/3983 [01:15<40:41,  1.59it/s]\u001B[A\n",
      "Iteration:   2% 95/3983 [01:16<40:01,  1.62it/s]\u001B[A\n",
      "Iteration:   2% 96/3983 [01:16<40:29,  1.60it/s]\u001B[A\n",
      "Iteration:   2% 97/3983 [01:17<39:51,  1.62it/s]\u001B[A\n",
      "Iteration:   2% 98/3983 [01:17<39:23,  1.64it/s]\u001B[A\n",
      "Iteration:   2% 99/3983 [01:18<39:05,  1.66it/s]\u001B[A\n",
      "Iteration:   3% 100/3983 [01:19<40:02,  1.62it/s]\u001B[A\n",
      "Iteration:   3% 101/3983 [01:19<39:39,  1.63it/s]\u001B[A\n",
      "Iteration:   3% 102/3983 [01:20<39:21,  1.64it/s]\u001B[A\n",
      "Iteration:   3% 103/3983 [01:21<51:14,  1.26it/s]\n",
      "Epoch:   0% 0/1 [01:21<?, ?it/s]\n",
      "03/02/2021 03:25:01 - INFO - __main__ -    global_step = 26, average loss = 9.313026318183312\n",
      "03/02/2021 03:25:01 - INFO - __main__ -   Saving model checkpoint to models/output\n",
      "03/02/2021 03:25:01 - INFO - transformers.configuration_utils -   Configuration saved in models/output/config.json\n",
      "03/02/2021 03:25:03 - INFO - transformers.modeling_utils -   Model weights saved in models/output/pytorch_model.bin\n",
      "03/02/2021 03:25:03 - INFO - transformers.configuration_utils -   loading configuration file models/output/config.json\n",
      "03/02/2021 03:25:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/02/2021 03:25:03 - INFO - transformers.modeling_utils -   loading weights file models/output/pytorch_model.bin\n",
      "03/02/2021 03:25:09 - INFO - transformers.configuration_utils -   loading configuration file models/output/config.json\n",
      "03/02/2021 03:25:09 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   Model name 'models/output' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'models/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   Didn't find file models/output/added_tokens.json. We won't load it.\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   loading file models/output/vocab.json\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   loading file models/output/merges.txt\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   loading file models/output/special_tokens_map.json\n",
      "03/02/2021 03:25:09 - INFO - transformers.tokenization_utils -   loading file models/output/tokenizer_config.json\n",
      "03/02/2021 03:25:09 - INFO - __main__ -   Evaluate the following checkpoints: ['models/output']\n",
      "03/02/2021 03:25:09 - INFO - transformers.configuration_utils -   loading configuration file models/output/config.json\n",
      "03/02/2021 03:25:09 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/02/2021 03:25:09 - INFO - transformers.modeling_utils -   loading weights file models/output/pytorch_model.bin\n",
      "03/02/2021 03:25:15 - INFO - __main__ -   Creating features from dataset file at data\n",
      "03/02/2021 03:25:15 - INFO - __main__ -   Saving features into cached file data/roberta_cached_lm_510_dev.txt\n",
      "03/02/2021 03:25:15 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "03/02/2021 03:25:15 - INFO - __main__ -     Num examples = 0\n",
      "03/02/2021 03:25:15 - INFO - __main__ -     Batch size = 4\n",
      "Evaluating: 0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"run_language_modeling.py\", line 783, in <module>\n",
      "    main()\n",
      "  File \"run_language_modeling.py\", line 775, in main\n",
      "    result = evaluate(args, model, tokenizer, prefix=prefix)\n",
      "  File \"run_language_modeling.py\", line 448, in evaluate\n",
      "    eval_loss = eval_loss / nb_eval_steps\n",
      "ZeroDivisionError: float division by zero\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7XOgCMcnwWwP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656,
     "referenced_widgets": [
      "5b1f275ef9c14e61ba49fc0c4339246e",
      "fe79529002814a14a8544041629b2719",
      "a653270828a14d3fa156f84a90248388",
      "90cff94cc1b64e7fa6f96bae187e61f1",
      "956c1906c7de475f96f49ff1ee4bd6ab",
      "e5e501748f9643b889bfb70062468af7",
      "66dc7919cfee4778a77c0ff02e773730",
      "68d717f04b904031900c9efa5a7b48e6",
      "81bd0fe9a64d43efa1f44dff2eb0a9f0",
      "1de72cce7e534381a02bab14c90e1c50",
      "684f0eafadb848cab61e2716f00ecb3c",
      "02a4648bafd94a7795def83cf6543715",
      "9abaf0ba7b064fb1bd4bb8a2ae2a2a59",
      "131d1f02c6544c5fa2061dae9d890498",
      "08213ab37c47495abe05edd80430ef98",
      "69d792d8132c408c99d461f3c740c805",
      "bd4011d5955c4a96b315f949132cd633",
      "ed5a2cb7bb9b4cdcbefee866e5e7db50",
      "9adaf55eeed0469c857e70eea521bc56",
      "c0a7137a4c91410999a07d61f240de97",
      "3340b5b3233c4865aa9dfad057a8e809",
      "76133744796a478da48c83406d6ae575",
      "a538bae985b8402db2852ac9abb17ca2",
      "d14664c3c23e4f7d9cccfbc7b388f446",
      "a04031238f6746d7bf3c371aed1bb690",
      "0dde75f5a08b4c9e8133bb0d586dd0ba",
      "0f2ef289110e41c2810e9c436fe18415",
      "016bd1d96c1342b7b76c0aebfcbe8cf7",
      "2d2bb4107ab0402c9189cbe391a2d006",
      "df0892f3773e4bc08da3ea1adb51b69b",
      "8aff1b6f9b784a2f82d6dcbda2b72a15",
      "3bcf2880f6d54af2846f15c48d47aa62",
      "008e5e38315c4a7cbb03f7f579812690",
      "6844b9a0e10d438ab86c7f20d4a145d0",
      "64f40dbb1e3a4b87933e64f72a224507",
      "20d2187dfc94492985d4b3aa8aad2352",
      "34770b3ee4dc40b4a5db4191f8d15657",
      "24bc4f6d88bf4bd6a9ac9e6292ff7c20",
      "f0f990ce9c9f4f99ab40ad98539c9b0f",
      "7ab3badac027410f87ac1425795c71f7"
     ]
    },
    "outputId": "095c5646-078c-43ba-d4a7-4ba282f4eec4"
   },
   "source": [
    "#using out trined model to predicted masked words\n",
    "#note: masked words are words we predict to occur next in the string based on\n",
    "# the context provided by the adjacent words\n",
    "\"\"\"\n",
    "Masked Word Example:\n",
    "Input: \"I have watched this [MASK] and it was awesome.\"\n",
    "Output: \"I have watched this movie and it was awesome.\" \n",
    "\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"chriskhanhtran/spanberta\",\n",
    "    tokenizer=\"chriskhanhtran/spanberta\"\n",
    ")\n",
    "\n",
    "fill_mask(\"Lavarse frecuentemente las manos con agua y <mask>.\")"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1f275ef9c14e61ba49fc0c4339246e",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=487.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bd0fe9a64d43efa1f44dff2eb0a9f0",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=954339.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4011d5955c4a96b315f949132cd633",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512068.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04031238f6746d7bf3c371aed1bb690",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=16.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Model name 'chriskhanhtran/spanberta' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased, google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/chriskhanhtran/spanberta/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008e5e38315c4a7cbb03f7f579812690",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501202014.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/pipelines.py:679: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  masked_index = (input_ids == self.tokenizer.mask_token_id).nonzero().item()\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'score': 0.6469604969024658,\n",
       "  'sequence': '<s> Lavarse frecuentemente las manos con agua y jabÃ³n.</s>',\n",
       "  'token': 18493},\n",
       " {'score': 0.06074365973472595,\n",
       "  'sequence': '<s> Lavarse frecuentemente las manos con agua y sal.</s>',\n",
       "  'token': 619},\n",
       " {'score': 0.029788149520754814,\n",
       "  'sequence': '<s> Lavarse frecuentemente las manos con agua y vapor.</s>',\n",
       "  'token': 11079},\n",
       " {'score': 0.0264101754873991,\n",
       "  'sequence': '<s> Lavarse frecuentemente las manos con agua y limÃ³n.</s>',\n",
       "  'token': 12788},\n",
       " {'score': 0.01702934503555298,\n",
       "  'sequence': '<s> Lavarse frecuentemente las manos con agua y vinagre.</s>',\n",
       "  'token': 18424}]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsxG8sMc-ull"
   },
   "source": [
    "# Conclusion: The model is able to interpolate Spanish!\n",
    "\n",
    "In our sentence:\n",
    "\n",
    "* \"Lavarse frecuentemente las manos con agua y <mask>\" \n",
    "\n",
    "* Translation: Frequently wash your hands with water and BLANK\n",
    "\n",
    "The model was able to predict plausbile words for the blank fill in:\n",
    "\n",
    "\n",
    "1.   jabÃ³n (water)\n",
    "2.   sal (salt)\n",
    "3.   vapor (steam)\n",
    "4.   limÃ³n (lemon)\n",
    "5.   vinagre (vinegar)\n",
    "\n"
   ]
  }
 ]
}